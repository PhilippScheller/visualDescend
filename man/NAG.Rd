% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim.NAG.R
\name{NAG}
\alias{NAG}
\title{Optimize mathematical function using Nesterov Accelerated Gradient (NAG)}
\usage{
NAG(
  f,
  x0,
  max.iter = 100,
  step.size = 0.001,
  phi = 0.8,
  stop.grad = .Machine$double.eps
)
}
\arguments{
\item{f}{a (multi-) dimensional function to be eptimized.}

\item{x0}{the starting point of the optimization.}

\item{max.iter}{the maximum number of iterations performed in the optimization.}

\item{step.size}{the step size (sometimes referred to as 'learn-rate') of the optimization.}

\item{phi}{controls the weight of the prior gradient contribution in the velocity.}

\item{stop.grad}{the stop-criterion for the gradient change.}
}
\description{
This functions uses the Nesterov Accelerated Gradient (NAG) to find
the minimum of a (multi-) dimensional mathematical function. The parameter
'phi' controls for the weight of prior gradients thus indirectly steering
the velocity of the algorithm.
}
