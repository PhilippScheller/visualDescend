% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim.gradientdescent.R
\name{grad.descent}
\alias{grad.descent}
\title{Optimize mathematical function using gradient descent}
\usage{
\method{grad}{descent}(f, x0, max.iter = 100, step.size = 0.01,
  stop.grad = .Machine$double.eps)
}
\arguments{
\item{f}{a (multi-) dimensional function to be eptimized.}

\item{x0}{the starting point of the optimization.}

\item{max.iter}{the maximum number of iterations performed in the optimization}

\item{step.size}{the step size (sometimes referred to as 'learn-rate') of the optimization.}

\item{stop.grad}{the stop-criterion for the gradient change.}
}
\description{
This functions uses the gradient descent algorithm to find the minimum of a
(multi-) dimensional mathematical function.
}
