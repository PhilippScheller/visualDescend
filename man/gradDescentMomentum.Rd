% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim.momentum.R
\name{gradDescentMomentum}
\alias{gradDescentMomentum}
\title{Optimize mathematical function using gradient descent with momentum}
\usage{
gradDescentMomentum(
  f,
  x0,
  max.iter = 100,
  step.size = 0.01,
  phi = 0.5,
  stop.grad = .Machine$double.eps
)
}
\arguments{
\item{f}{a (multi-) dimensional function to be eptimized.}

\item{x0}{the starting point of the optimization.}

\item{max.iter}{the maximum number of iterations performed in the optimization.}

\item{step.size}{the step size (sometimes referred to as 'learn-rate') of the optimization.}

\item{phi}{controls the weight of the prior gradient contribution in the velocity.}

\item{stop.grad}{the stop-criterion for the gradient change.}
}
\description{
This functions uses the gradient descent algorithm with momentum to find
the minimum of a (multi-) dimensional mathematical function. The parameter
'phi' controls for the weight of prior gradients thus indirectly steering
the velocity of the algorithm.
}
